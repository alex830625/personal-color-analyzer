from dotenv import load_dotenv
load_dotenv()
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import cv2
import numpy as np
from io import BytesIO
import colorsys
import dlib
import os
import uuid
import urllib.request
import bz2
import google.generativeai as genai
import json
import re
from bisenet import load_bisenet_model
import torch

app = Flask(__name__)
CORS(app)

# Ensure 'uploads' and 'debug_output' directories exist
UPLOADS_DIR = os.path.join(os.path.dirname(__file__), 'uploads')
DEBUG_OUTPUT_DIR = os.path.join(os.path.dirname(__file__), 'debug_output')
os.makedirs(UPLOADS_DIR, exist_ok=True)
os.makedirs(DEBUG_OUTPUT_DIR, exist_ok=True)

WEIGHT_PATH = os.path.join(os.path.dirname(__file__), '79999_iter.pth')
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
bisenet_model = load_bisenet_model(WEIGHT_PATH, device=DEVICE, n_classes=19)

print("æ¨¡å‹æ¬Šé‡è·¯å¾‘ï¼š", WEIGHT_PATH)
print("æª”æ¡ˆæ˜¯å¦å­˜åœ¨ï¼š", os.path.exists(WEIGHT_PATH))

def download_dlib_model():
    """ä¸‹è¼‰ dlib è‡‰éƒ¨ç‰¹å¾µé»æ¨¡å‹"""
    model_file = 'shape_predictor_68_face_landmarks.dat'
    if os.path.exists(model_file):
        print("âœ… dlib æ¨¡å‹æª”æ¡ˆå·²å­˜åœ¨")
        return True
    
    print("ğŸ“¥ æ­£åœ¨ä¸‹è¼‰ dlib æ¨¡å‹æª”æ¡ˆ...")
    model_url = "http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2"
    compressed_file = "shape_predictor_68_face_landmarks.dat.bz2"
    
    try:
        # ä¸‹è¼‰å£“ç¸®æª”æ¡ˆ
        urllib.request.urlretrieve(model_url, compressed_file)
        print("âœ… æ¨¡å‹æª”æ¡ˆä¸‹è¼‰å®Œæˆ")
        
        # è§£å£“ç¸®
        with bz2.open(compressed_file, 'rb') as source, open(model_file, 'wb') as target:
            target.write(source.read())
        print("âœ… æ¨¡å‹æª”æ¡ˆè§£å£“ç¸®å®Œæˆ")
        
        # æ¸…ç†å£“ç¸®æª”æ¡ˆ
        os.remove(compressed_file)
        print("âœ… æ¸…ç†å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰æ¨¡å‹æª”æ¡ˆå¤±æ•—: {e}")
        return False

# æª¢æŸ¥ä¸¦ä¸‹è¼‰ dlib æ¨¡å‹
if not download_dlib_model():
    print("âš ï¸ ç„¡æ³•ä¸‹è¼‰ dlib æ¨¡å‹ï¼Œè«‹æ‰‹å‹•ä¸‹è¼‰ shape_predictor_68_face_landmarks.dat")
    print("ä¸‹è¼‰ç¶²å€: http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2")

# åˆå§‹åŒ– dlib çš„è‡‰éƒ¨åµæ¸¬å™¨å’Œç‰¹å¾µé»é æ¸¬å™¨
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor('shape_predictor_81_face_landmarks.dat')
print("âœ… dlib æ¨¡å‹è¼‰å…¥æˆåŠŸ")

def rgb_to_hsv(rgb):
    """å°‡RGBè½‰æ›ç‚ºHSV"""
    r, g, b = rgb[0]/255.0, rgb[1]/255.0, rgb[2]/255.0
    return colorsys.rgb_to_hsv(r, g, b)

def hsv_to_rgb(hsv):
    """å°‡HSVè½‰æ›ç‚ºRGB"""
    r, g, b = colorsys.hsv_to_rgb(hsv[0], hsv[1], hsv[2])
    return (int(r*255), int(g*255), int(b*255))

def get_dominant_colors(image, k=1, mask=None):
    """
    ç²å–æŒ‡å®šé®ç½©å€åŸŸçš„ã€Œå¹³å‡é¡è‰²ã€ã€‚
    """
    
    # å¦‚æœæ²’æœ‰é®ç½©ï¼Œç›´æ¥å›å‚³é è¨­é¡è‰² (é¿å…è¨ˆç®—æ•´å¼µåœ–çš„å¹³å‡è‰²)
    if mask is None:
        return [(128, 128, 128)]
    
    # ä½¿ç”¨ cv2.mean è¨ˆç®—é®ç½©å€åŸŸçš„å¹³å‡ BGR å€¼
    # mean() å›å‚³ (B, G, R, Alpha)
    mean_bgr = cv2.mean(image, mask=mask)
    
    # **é—œéµä¿®æ­£**ï¼šå°‡ BGR è½‰æ›ç‚º RGB
    # mean_bgr[0] æ˜¯ B, [1] æ˜¯ G, [2] æ˜¯ R
    mean_rgb = (mean_bgr[2], mean_bgr[1], mean_bgr[0])

    # å°‡çµæœæ”¾å…¥ä¸€å€‹ list ä¸­ï¼Œä»¥ç¬¦åˆå‡½å¼åŸæœ‰çš„å›å‚³æ ¼å¼
    # å°‡é¡è‰²è½‰æ›ç‚ºæ•´æ•¸å…ƒçµ„
    dominant_color = [tuple(map(int, mean_rgb))]
    
    return dominant_color

def detect_face_landmarks(image):
    """æª¢æ¸¬è‡‰éƒ¨ç‰¹å¾µé»"""
    if predictor is None:
        print("âŒ dlib æ¨¡å‹æœªè¼‰å…¥ï¼Œç„¡æ³•é€²è¡Œè‡‰éƒ¨ç‰¹å¾µé»æª¢æ¸¬")
        return None, None
    
    # è½‰æ›ç‚ºç°åº¦åœ–
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # æª¢æ¸¬è‡‰éƒ¨
    faces = detector(gray)
    
    if len(faces) == 0:
        return None, None
    
    # å–ç¬¬ä¸€å€‹æª¢æ¸¬åˆ°çš„è‡‰éƒ¨
    face = faces[0]
    
    # ç²å–68å€‹ç‰¹å¾µé»
    landmarks = predictor(gray, face)
    
    return face, landmarks

def get_landmark_points(landmarks):
    """å°‡ dlib landmarks è½‰æ›ç‚º (x, y) åº§æ¨™é»çš„ list"""
    points = []
    for i in range(landmarks.num_parts):
        point = landmarks.part(i)
        points.append((point.x, point.y))
    return points

def extract_skin_region(image, landmarks):
    """
    é‡å° 81 é»æ¨¡å‹å„ªåŒ–è‡‰å‹/ä¸‹å·´é®ç½©ï¼Œè‹¥ä¸è¶³81é»å‰‡fallbackå›68é»é®ç½©ã€‚
    """
    if landmarks is None:
        return None
    points = get_landmark_points(landmarks)
    if len(points) >= 82:  # 81é»æ¨¡å‹
        jaw_points = [*range(0, 17), 79, 80, 81]
        jaw_pts = np.array([points[i] for i in jaw_points if i < len(points)], dtype=np.int32)
        face_mask = np.zeros(image.shape[:2], dtype=np.uint8)
        cv2.fillConvexPoly(face_mask, cv2.convexHull(jaw_pts), 255)
        # æ’é™¤äº”å®˜
        cv2.fillConvexPoly(face_mask, np.array(points[36:42], dtype=np.int32), 0)
        cv2.fillConvexPoly(face_mask, np.array(points[42:48], dtype=np.int32), 0)
        cv2.fillConvexPoly(face_mask, np.array(points[17:22], dtype=np.int32), 0)
        cv2.fillConvexPoly(face_mask, np.array(points[22:27], dtype=np.int32), 0)
        # å˜´å”‡ï¼ˆæ–°ï¼š48-67+69-78ï¼‰
        lip_points = [*range(48, 68), *range(69, 79)]
        lip_pts = np.array([points[i] for i in lip_points if i < len(points)], dtype=np.int32)
        cv2.fillConvexPoly(face_mask, lip_pts, 0)
        return face_mask
    else:  # fallback 68é»
        face_outline_pts = np.array(points[0:17], dtype=np.int32)
        face_mask = np.zeros(image.shape[:2], dtype=np.uint8)
        cv2.fillConvexPoly(face_mask, cv2.convexHull(face_outline_pts), 255)
        # æ’é™¤äº”å®˜
        cv2.fillConvexPoly(face_mask, np.array(points[36:42], dtype=np.int32), 0)
        cv2.fillConvexPoly(face_mask, np.array(points[42:48], dtype=np.int32), 0)
        cv2.fillConvexPoly(face_mask, np.array(points[17:22], dtype=np.int32), 0)
        cv2.fillConvexPoly(face_mask, np.array(points[22:27], dtype=np.int32), 0)
        cv2.fillConvexPoly(face_mask, np.array(points[48:68], dtype=np.int32), 0)
        return face_mask

def extract_eye_regions(image, landmarks):
    """æå–çœ¼ç›å€åŸŸ"""
    if landmarks is None:
        return []
    
    points = get_landmark_points(landmarks)
    eye_regions = []
    
    # å·¦çœ¼ (36-41)
    left_eye_points = np.array(points[36:42], dtype=np.int32)
    # å³çœ¼ (42-47)
    right_eye_points = np.array(points[42:48], dtype=np.int32)
    
    for eye_points in [left_eye_points, right_eye_points]:
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        
        # ä½¿ç”¨å‡¸åŒ…æ›´ç²¾æº–æ¡†é¸çœ¼ç›
        hull = cv2.convexHull(eye_points)
        cv2.fillConvexPoly(mask, hull, 255)
        eye_regions.append(mask)
    
    return eye_regions

def extract_lip_region(image, landmarks):
    """
    é‡å° 81 é»æ¨¡å‹å„ªåŒ–å˜´å”‡é®ç½©ï¼Œè‹¥ä¸è¶³81é»å‰‡fallbackå›68é»é®ç½©ã€‚
    """
    if landmarks is None:
        return None
    points = get_landmark_points(landmarks)
    if len(points) >= 79:  # 81é»æ¨¡å‹
        lip_points = [*range(48, 68), *range(69, 79)]
        lip_pts = np.array([points[i] for i in lip_points if i < len(points)], dtype=np.int32)
        hull = cv2.convexHull(lip_pts)
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        cv2.fillConvexPoly(mask, hull, 255)
        return mask
    else:  # fallback 68é»
        lip_points = np.array(points[48:68], dtype=np.int32)
        hull = cv2.convexHull(lip_points)
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        cv2.fillConvexPoly(mask, hull, 255)
        return mask

def extract_hair_mask_bisenet(image):
    import cv2
    import torch
    h, w = image.shape[:2]
    # BiSeNet è¼¸å…¥éœ€ 512x512
    img_resized = cv2.resize(image, (512, 512))
    img_tensor = torch.from_numpy(img_resized.transpose(2, 0, 1)).unsqueeze(0).float().to(DEVICE) / 255.0
    with torch.no_grad():
        out = bisenet_model(img_tensor)[0]
        parsing = out.squeeze(0).cpu().numpy().argmax(0)
    # å–å‡ºé ­é«®å€åŸŸ
    hair_mask = (parsing == 17).astype(np.uint8) * 255
    # é‚„åŸåˆ°åŸåœ–å¤§å°
    hair_mask_full = cv2.resize(hair_mask, (w, h), interpolation=cv2.INTER_NEAREST)
    return hair_mask_full

def gray_world_white_balance(img):
    # ç°ä¸–ç•Œå‡è¨­è‡ªå‹•ç™½å¹³è¡¡
    img = img.astype(np.float32)
    avg_b = np.mean(img[:,:,0])
    avg_g = np.mean(img[:,:,1])
    avg_r = np.mean(img[:,:,2])
    avg_gray = (avg_b + avg_g + avg_r) / 3
    scale_b = avg_gray / avg_b
    scale_g = avg_gray / avg_g
    scale_r = avg_gray / avg_r
    img[:,:,0] *= scale_b
    img[:,:,1] *= scale_g
    img[:,:,2] *= scale_r
    img = np.clip(img, 0, 255).astype(np.uint8)
    return img

def mask_skin_pixels(image, mask):
    # YCrCb è†šè‰²åƒç´ éæ¿¾
    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)
    lower = np.array([0, 133, 77], dtype=np.uint8)
    upper = np.array([255, 173, 127], dtype=np.uint8)
    skin_mask = cv2.inRange(ycrcb, lower, upper)
    combined = cv2.bitwise_and(mask, skin_mask)
    # Debug: å°å‡ºè†šè‰²åƒç´ æ•¸é‡èˆ‡å¹³å‡ BGR
    skin_pixels = image[combined > 0]
    print(f"[è†šè‰²éæ¿¾ debug] è†šè‰²åƒç´ æ•¸é‡: {len(skin_pixels)}")
    if len(skin_pixels) > 0:
        mean_bgr = np.mean(skin_pixels, axis=0)
        print(f"[è†šè‰²éæ¿¾ debug] è†šè‰²åƒç´ å¹³å‡ BGR: {mean_bgr}")
    else:
        print("[è†šè‰²éæ¿¾ debug] ç„¡è†šè‰²åƒç´ ")
    return combined

def calculate_skin_tone(image, landmarks):
    """
    ä¸€æ¬¡æ€§å„ªåŒ–ï¼šè‡ªå‹•ç™½å¹³è¡¡ã€LABè‰²ç©ºé–“ã€äº”å€åˆ†å€ã€è†šè‰²åƒç´ éæ¿¾ã€åŠ æ¬Šå¹³å‡
    """
    if landmarks is None:
        return (128, 128, 128)
    # 1. è‡ªå‹•ç™½å¹³è¡¡
    image = gray_world_white_balance(image)
    points = get_landmark_points(landmarks)
    h, w = image.shape[:2]
    # 2. å»ºç«‹äº”å€é®ç½©
    masks = {}
    # é¡é ­
    masks['forehead'] = np.zeros((h, w), dtype=np.uint8)
    if len(points) >= 79:
        forehead_pts = np.array([points[i] for i in range(69, 79) if i < len(points)], dtype=np.int32)
        if len(forehead_pts) > 2:
            cv2.fillConvexPoly(masks['forehead'], forehead_pts, 255)
    else:
        if all(p in range(len(points)) for p in [19, 24, 27, 0, 16, 28]):
            face_width = points[16][0] - points[0][0]
            forehead_height_ref_y = (points[19][1] + points[24][1]) // 2
            forehead_height = abs(points[28][1] - forehead_height_ref_y)
            ellipse_center_y = forehead_height_ref_y - forehead_height
            cv2.ellipse(masks['forehead'], (points[27][0], ellipse_center_y), (int(face_width * 0.35), forehead_height), 0, 0, 360, 255, -1)
    # å·¦è‡‰é °
    masks['left_cheek'] = np.zeros((h, w), dtype=np.uint8)
    if all(p in range(len(points)) for p in [1, 2, 3, 4, 31, 48]):
        left_cheek_pts = np.array([points[1], points[2], points[3], points[4], points[31], points[48]], dtype=np.int32)
        cv2.fillPoly(masks['left_cheek'], [left_cheek_pts], 255)
    # å³è‡‰é °
    masks['right_cheek'] = np.zeros((h, w), dtype=np.uint8)
    if all(p in range(len(points)) for p in [15, 14, 13, 12, 35, 54]):
        right_cheek_pts = np.array([points[15], points[14], points[13], points[12], points[35], points[54]], dtype=np.int32)
        cv2.fillPoly(masks['right_cheek'], [right_cheek_pts], 255)
    # é¼»æ¨‘
    masks['nose'] = np.zeros((h, w), dtype=np.uint8)
    if all(p in range(len(points)) for p in [27, 28, 29, 30, 33]):
        nose_pts = np.array([points[27], points[28], points[29], points[30], points[33]], dtype=np.int32)
        cv2.fillConvexPoly(masks['nose'], nose_pts, 255)
    # ä¸‹å·´
    masks['chin'] = np.zeros((h, w), dtype=np.uint8)
    if all(p in range(len(points)) for p in [6, 7, 8, 9, 57]):
        chin_pts = np.array([points[6], points[7], points[8], points[9], points[57]], dtype=np.int32)
        cv2.fillConvexPoly(masks['chin'], chin_pts, 255)
    # 3. æ¯å€é®ç½©å…§è†šè‰²åƒç´ éæ¿¾ & LABå¹³å‡
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    means = {}
    for k in masks:
        filtered_mask = mask_skin_pixels(image, masks[k])
        if np.any(filtered_mask):
            mean_lab = cv2.mean(lab, mask=filtered_mask)[:3]
        else:
            mean_lab = (0,0,0)
        means[k] = mean_lab
    # 4. åŠ æ¬Šå¹³å‡ï¼ˆè‡‰é °å„20%ã€é¡é ­20%ã€é¼»æ¨‘20%ã€ä¸‹å·´20%ï¼‰
    final_L = (means['left_cheek'][0] * 0.2 + means['right_cheek'][0] * 0.2 + means['forehead'][0] * 0.2 + means['nose'][0] * 0.2 + means['chin'][0] * 0.2)
    final_A = (means['left_cheek'][1] * 0.2 + means['right_cheek'][1] * 0.2 + means['forehead'][1] * 0.2 + means['nose'][1] * 0.2 + means['chin'][1] * 0.2)
    final_B = (means['left_cheek'][2] * 0.2 + means['right_cheek'][2] * 0.2 + means['forehead'][2] * 0.2 + means['nose'][2] * 0.2 + means['chin'][2] * 0.2)
    # 5. ç›´æ¥ç”¨ OpenCV LABï¼ˆä¸åšç¸®æ”¾/åç§»ï¼‰
    avg_lab = np.uint8([[[final_L, final_A, final_B]]])
    avg_bgr = cv2.cvtColor(avg_lab, cv2.COLOR_LAB2BGR)[0,0]
    avg_rgb = (int(avg_bgr[2]), int(avg_bgr[1]), int(avg_bgr[0]))
    # Debug log
    print("[è†šè‰²åˆ†æ debug]")
    for k in means:
        print(f"å€åŸŸ {k} LAB: {means[k]}")
    print(f"åŠ æ¬Šå¹³å‡ LAB: ({final_L}, {final_A}, {final_B})")
    print(f"æœ€çµ‚ RGB: {avg_rgb}")
    return avg_rgb

def create_debug_image_dlib(image, face_rect, skin_mask, eye_masks, lip_mask, hair_mask, output_path):
    """ä½¿ç”¨ dlib çš„é®ç½©å»ºç«‹é«˜ç²¾åº¦åµéŒ¯åœ–"""
    debug_img = image.copy()

    # å®šç¾©é¡è‰² (BGR æ ¼å¼)
    SKIN_COLOR = (0, 255, 255)  # Yellow
    EYE_COLOR = (255, 0, 0)      # Blue
    LIP_COLOR = (0, 0, 255)    # Red
    HAIR_COLOR = (42, 42, 165)   # Brown
    FACE_RECT_COLOR = (0, 255, 0) # Green

    # ç–ŠåŠ é¡è‰²é®ç½©
    # çš®è†š
    if skin_mask is not None:
        skin_overlay = np.zeros_like(debug_img)
        skin_overlay[skin_mask == 255] = SKIN_COLOR
        cv2.addWeighted(debug_img, 1, skin_overlay, 0.4, 0, debug_img)
    # çœ¼ç›
    if eye_masks:
        for eye_mask in eye_masks:
            eye_overlay = np.zeros_like(debug_img)
            eye_overlay[eye_mask == 255] = EYE_COLOR
            cv2.addWeighted(debug_img, 1, eye_overlay, 0.6, 0, debug_img)
    # å˜´å”‡
    if lip_mask is not None:
        lip_overlay = np.zeros_like(debug_img)
        lip_overlay[lip_mask == 255] = LIP_COLOR
        cv2.addWeighted(debug_img, 1, lip_overlay, 0.5, 0, debug_img)
    # é ­é«®
    if hair_mask is not None:
        hair_overlay = np.zeros_like(debug_img)
        hair_overlay[hair_mask == 255] = HAIR_COLOR
        cv2.addWeighted(debug_img, 1, hair_overlay, 0.4, 0, debug_img)

    # ç¹ªè£½è‡‰éƒ¨çŸ©å½¢æ¡†
    if face_rect:
        x, y, w, h = face_rect.left(), face_rect.top(), face_rect.width(), face_rect.height()
        cv2.rectangle(debug_img, (x, y), (x + w, y + h), FACE_RECT_COLOR, 2)

    # å„²å­˜åµéŒ¯åœ–
    cv2.imwrite(output_path, debug_img)
    print(f"âœ… åµéŒ¯åœ–å·²å„²å­˜è‡³: {output_path}")

def create_debug_mask_image(image, skin_mask=None, eye_masks=None, lip_mask=None, hair_mask=None, output_path='debug_mask.png'):
    debug_img = image.copy()
    # å®šç¾©é¡è‰² (BGR)
    SKIN_COLOR = (0, 255, 255)  # é»ƒ
    EYE_COLOR = (255, 0, 0)     # è—
    LIP_COLOR = (0, 0, 255)     # ç´…
    HAIR_COLOR = (128, 0, 128)  # ç´«
    # Debug: è¼¸å‡º hair_mask çš„å”¯ä¸€å€¼
    print('hair_mask unique:', np.unique(hair_mask) if hair_mask is not None else None)
    # ç–ŠåŠ é®ç½©
    if skin_mask is not None:
        skin_overlay = np.zeros_like(debug_img)
        skin_overlay[skin_mask == 255] = SKIN_COLOR
        cv2.addWeighted(debug_img, 1, skin_overlay, 0.4, 0, debug_img)
    if eye_masks:
        for eye_mask in eye_masks:
            eye_overlay = np.zeros_like(debug_img)
            eye_overlay[eye_mask == 255] = EYE_COLOR
            cv2.addWeighted(debug_img, 1, eye_overlay, 0.6, 0, debug_img)
    if lip_mask is not None:
        lip_overlay = np.zeros_like(debug_img)
        lip_overlay[lip_mask == 255] = LIP_COLOR
        cv2.addWeighted(debug_img, 1, lip_overlay, 0.5, 0, debug_img)
    if hair_mask is not None:
        hair_overlay = np.zeros_like(debug_img)
        hair_overlay[hair_mask == 255] = HAIR_COLOR
        cv2.addWeighted(debug_img, 1, hair_overlay, 0.4, 0, debug_img)
    cv2.imwrite(output_path, debug_img)
    print(f"âœ… é®ç½©åœ–å·²å„²å­˜è‡³: {output_path}")

def analyze_seasonal_colors(skin_tone, eye_color, hair_color):
    """åˆ†æå­£ç¯€æ€§è‰²å½©"""
    # è½‰æ›ç‚ºHSVé€²è¡Œåˆ†æ
    skin_hsv = rgb_to_hsv(skin_tone)
    eye_hsv = rgb_to_hsv(eye_color)
    hair_hsv = rgb_to_hsv(hair_color)
    
    # åˆ†æè†šè‰²çš„è‰²èª¿å’Œé£½å’Œåº¦
    skin_hue = skin_hsv[0] * 360  # è½‰æ›ç‚ºåº¦æ•¸
    skin_sat = skin_hsv[1]
    skin_val = skin_hsv[2]
    
    # å­£ç¯€æ€§è‰²å½©åˆ¤æ–·é‚è¼¯
    if skin_hue < 30 or skin_hue > 330:  # åç´…/æ©™
        if skin_sat > 0.3:  # é£½å’Œåº¦è¼ƒé«˜
            season = "spring"
        else:
            season = "autumn"
    elif 30 <= skin_hue <= 90:  # åé»ƒ
        if skin_val > 0.6:  # äº®åº¦è¼ƒé«˜
            season = "spring"
        else:
            season = "autumn"
    elif 90 <= skin_hue <= 150:  # åç¶ 
        season = "summer"
    elif 150 <= skin_hue <= 270:  # åè—/ç´«
        season = "winter"
    else:  # 270-330 åç´«/ç´…
        season = "winter"
    
    return season, {
        'skin_hsv': skin_hsv,
        'eye_hsv': eye_hsv,
        'hair_hsv': hair_hsv
    }

def get_color_palette(season):
    """æ ¹æ“šå­£ç¯€ç²å–å»ºè­°è‰²æ¿"""
    palettes = {
        "spring": {
            "clothes": ["#FF6B6B", "#4ECDC4", "#45B7D1", "#96CEB4", "#FFEAA7"],
            "makeup": ["#FFB6C1", "#FFC0CB", "#FF69B4", "#FF1493", "#DC143C"],
            "jewelry": ["#FFD700", "#FFA500", "#FF6347", "#FF4500"],
            "avoid": ["#000080", "#191970", "#483D8B", "#6A5ACD"]
        },
        "summer": {
            "clothes": ["#87CEEB", "#98FB98", "#DDA0DD", "#F0E68C", "#FFB6C1"],
            "makeup": ["#E6E6FA", "#D8BFD8", "#DDA0DD", "#EE82EE", "#DA70D6"],
            "jewelry": ["#C0C0C0", "#E6E6FA", "#F0F8FF", "#F5F5DC"],
            "avoid": ["#FF4500", "#FF6347", "#FF8C00", "#FFA500"]
        },
        "autumn": {
            "clothes": ["#8B4513", "#A0522D", "#CD853F", "#D2691E", "#B8860B"],
            "makeup": ["#DEB887", "#F4A460", "#DAA520", "#B8860B", "#CD853F"],
            "jewelry": ["#B8860B", "#DAA520", "#CD853F", "#8B4513"],
            "avoid": ["#00CED1", "#40E0D0", "#48D1CC", "#20B2AA"]
        },
        "winter": {
            "clothes": ["#000080", "#191970", "#483D8B", "#6A5ACD", "#9370DB"],
            "makeup": ["#FF1493", "#DC143C", "#B22222", "#8B0000", "#FF4500"],
            "jewelry": ["#C0C0C0", "#FFFFFF", "#000000", "#4169E1"],
            "avoid": ["#FFD700", "#FFA500", "#FF6347", "#FF4500"]
        }
    }
    
    return palettes.get(season, palettes["spring"])

def rgb_to_hex(rgb):
    """å°‡RGBè½‰æ›ç‚ºåå…­é€²åˆ¶"""
    return '#%02x%02x%02x' % rgb

def get_color_names_from_gemini(hex_colors):
    genai.configure(api_key=os.environ["GEMINI_API_KEY"])
    prompt = (
        "è«‹å¹«æˆ‘åˆ¤æ–·ä»¥ä¸‹è‰²ç¢¼çš„ç¹é«”ä¸­æ–‡åç¨±ï¼Œå›å‚³æ ¼å¼ç‚º JSON ç‰©ä»¶ï¼Œkey ç‚ºè‰²ç¢¼ï¼Œvalue ç‚ºä¸­æ–‡åç¨±ï¼š\n"
        + ", ".join(hex_colors)
    )
    model = genai.GenerativeModel("gemini-2.5-flash")
    response = model.generate_content(prompt)
    # è§£æ Gemini å›å‚³çš„ JSON å…§å®¹
    match = re.search(r'\{.*\}', response.text, re.DOTALL)
    if match:
        return json.loads(match.group(0))
    else:
        return {c: "æœªçŸ¥è‰²å" for c in hex_colors}

@app.route('/analyze', methods=['POST'])
def analyze():
    if 'photo' not in request.files:
        return jsonify({"error": "è«‹æ±‚ä¸­ç¼ºå°‘åœ–ç‰‡æª”æ¡ˆ"}), 400
    file = request.files['photo']
    if file.filename == '':
        return jsonify({"error": "æœªé¸æ“‡æª”æ¡ˆ"}), 400

    # Save uploaded file
    filename = f"upload_{uuid.uuid4().hex}.jpg"
    file_path = os.path.join(UPLOADS_DIR, filename)
    file.save(file_path)

    # Read image
    image = cv2.imread(file_path)
    if image is None:
        return jsonify({"error": "ç„¡æ³•è®€å–åœ–ç‰‡æª”æ¡ˆ"}), 500

    try:
        # --- 1. Face and Landmark Detection ---
        face, landmarks = detect_face_landmarks(image)
        if landmarks is None:
            return jsonify({"error": "æœªåµæ¸¬åˆ°è‡‰éƒ¨ç‰¹å¾µé»ï¼Œè«‹ä½¿ç”¨æ›´æ¸…æ™°çš„æ­£é¢ç…§ã€‚"}), 400

        # --- 2. Analyze Colors using new method ---
        skin_tone = calculate_skin_tone(image, landmarks)
        
        eye_masks = extract_eye_regions(image, landmarks)
        lip_mask = extract_lip_region(image, landmarks)
        hair_mask = extract_hair_mask_bisenet(image)
        if hair_mask is not None:
            debug_hair_mask_path = os.path.join(DEBUG_OUTPUT_DIR, f"hair_mask_{uuid.uuid4().hex}.png")
            cv2.imwrite(debug_hair_mask_path, hair_mask)
            print(f"hair_mask saved to: {debug_hair_mask_path}, unique: {np.unique(hair_mask)}")
        if hair_mask is None:
            hair_mask = extract_hair_region(image, landmarks, face)
            if hair_mask is not None:
                debug_hair_mask_path = os.path.join(DEBUG_OUTPUT_DIR, f"hair_mask_fallback_{uuid.uuid4().hex}.png")
                cv2.imwrite(debug_hair_mask_path, hair_mask)
                print(f"hair_mask (fallback) saved to: {debug_hair_mask_path}, unique: {np.unique(hair_mask)}")
        
        all_eye_colors = []
        if eye_masks:
            for eye_mask in eye_masks:
                all_eye_colors.extend(get_dominant_colors(image, mask=eye_mask))
        eye_color = all_eye_colors[0] if all_eye_colors else (128, 128, 128)

        lip_color = get_dominant_colors(image, mask=lip_mask)[0] if lip_mask is not None else (128, 128, 128)
        hair_color = get_dominant_colors(image, mask=hair_mask)[0] if hair_mask is not None else (128, 128, 128)

        # --- 3. Gemini æŸ¥è©¢è‰²å ---
        hex_colors = [
            rgb_to_hex(skin_tone),
            rgb_to_hex(eye_color),
            rgb_to_hex(hair_color),
            rgb_to_hex(lip_color)
        ]
        color_names = get_color_names_from_gemini(hex_colors)

        # --- 4. Seasonal Analysis ---
        season, analysis_details = analyze_seasonal_colors(skin_tone, eye_color, hair_color)

        # --- 5. Create Debug Image ---
        skin_mask_for_debug = extract_skin_region(image, landmarks)
        debug_image_filename = f"debug_{uuid.uuid4().hex}.jpg"
        debug_image_path = os.path.join(DEBUG_OUTPUT_DIR, debug_image_filename)
        create_debug_image_dlib(image, face, skin_mask_for_debug, eye_masks, lip_mask, hair_mask, debug_image_path)
        debug_image_url = f"/debug/{debug_image_filename}"

        # --- 5.1. Create Debug Mask Image (for front-end overlay) ---
        debug_mask_filename = f"debug_mask_{uuid.uuid4().hex}.png"
        debug_mask_path = os.path.join(DEBUG_OUTPUT_DIR, debug_mask_filename)
        create_debug_mask_image(image, skin_mask_for_debug, eye_masks, lip_mask, hair_mask, debug_mask_path)
        debug_mask_url = f"/debug/{debug_mask_filename}"

        # --- 6. Prepare Response ---
        response_data = {
            "skin_tone": rgb_to_hex(skin_tone),
            "eye_color": rgb_to_hex(eye_color),
            "hair_color": rgb_to_hex(hair_color),
            "lip_color": rgb_to_hex(lip_color),
            "color_names": color_names,
            "season": season,
            "season_name": {"spring": "æ˜¥å­£å‹", "summer": "å¤å­£å‹", "autumn": "ç§‹å­£å‹", "winter": "å†¬å­£å‹"}.get(season, "åˆ†æå¤±æ•—"),
            "color_suggestions": get_color_palette(season),
            "analysis_details": analysis_details,
            "debug_image_url": debug_image_url,
            "debug_mask_url": debug_mask_url,
            "debug_error": ""
        }
        return jsonify(response_data)

    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"[!] Critical error in dlib analyze route: {e}")
        return jsonify({"error": f"ä¼ºæœå™¨åœ¨é€²éšåˆ†æä¸­ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}"}), 500
    finally:
        # Clean up the uploaded file
        if os.path.exists(file_path):
            os.remove(file_path)

@app.route('/debug/<filename>')
def serve_debug_image(filename):
    return send_from_directory(DEBUG_OUTPUT_DIR, filename)

if __name__ == '__main__':
    # ... (add predictor file check)
    app.run(host='0.0.0.0', port=5001)