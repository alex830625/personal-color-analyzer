from dotenv import load_dotenv
load_dotenv()
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import cv2
import numpy as np
from io import BytesIO
import colorsys
import dlib
import os
import uuid
import urllib.request
import bz2
import google.generativeai as genai
import json
import re
from bisenet import load_bisenet_model
import torch
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

app = Flask(__name__)
CORS(app)

# Ensure 'uploads' and 'debug_output' directories exist
UPLOADS_DIR = os.path.join(os.path.dirname(__file__), 'uploads')
DEBUG_OUTPUT_DIR = os.path.join(os.path.dirname(__file__), 'debug_output')
os.makedirs(UPLOADS_DIR, exist_ok=True)
os.makedirs(DEBUG_OUTPUT_DIR, exist_ok=True)

WEIGHT_PATH = os.path.join(os.path.dirname(__file__), '79999_iter.pth')
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# å…¨åŸŸæ¨¡å‹å¿«å–
_model_cache = {}
_model_lock = threading.Lock()

def get_bisenet_model():
    """å–å¾— BiSeNet æ¨¡å‹ï¼ˆä½¿ç”¨å¿«å–ï¼‰"""
    with _model_lock:
        if 'bisenet' not in _model_cache:
            print("ğŸ”„ è¼‰å…¥ BiSeNet æ¨¡å‹...")
            start_time = time.time()
            _model_cache['bisenet'] = load_bisenet_model(WEIGHT_PATH, device=DEVICE, n_classes=19)
            print(f"âœ… BiSeNet æ¨¡å‹è¼‰å…¥å®Œæˆï¼Œè€—æ™‚ {time.time() - start_time:.2f} ç§’")
        return _model_cache['bisenet']

# é è¼‰å…¥æ¨¡å‹
print("ğŸš€ é è¼‰å…¥ BiSeNet æ¨¡å‹...")
get_bisenet_model()

def download_dlib_model():
    """ä¸‹è¼‰ dlib è‡‰éƒ¨ç‰¹å¾µé»æ¨¡å‹"""
    model_file = 'shape_predictor_68_face_landmarks.dat'
    if os.path.exists(model_file):
        return True
    
    print("ğŸ“¥ æ­£åœ¨ä¸‹è¼‰ dlib æ¨¡å‹æª”æ¡ˆ...")
    model_url = "http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2"
    compressed_file = "shape_predictor_68_face_landmarks.dat.bz2"
    
    try:
        # ä¸‹è¼‰å£“ç¸®æª”æ¡ˆ
        urllib.request.urlretrieve(model_url, compressed_file)
        print("âœ… æ¨¡å‹æª”æ¡ˆä¸‹è¼‰å®Œæˆ")
        
        # è§£å£“ç¸®
        with bz2.open(compressed_file, 'rb') as source, open(model_file, 'wb') as target:
            target.write(source.read())
        print("âœ… æ¨¡å‹æª”æ¡ˆè§£å£“ç¸®å®Œæˆ")
        
        # æ¸…ç†å£“ç¸®æª”æ¡ˆ
        os.remove(compressed_file)
        print("âœ… æ¸…ç†å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰æ¨¡å‹æª”æ¡ˆå¤±æ•—: {e}")
        return False

# æª¢æŸ¥ä¸¦ä¸‹è¼‰ dlib æ¨¡å‹
if not download_dlib_model():
    print("âš ï¸ ç„¡æ³•ä¸‹è¼‰ dlib æ¨¡å‹ï¼Œè«‹æ‰‹å‹•ä¸‹è¼‰ shape_predictor_68_face_landmarks.dat")
    print("ä¸‹è¼‰ç¶²å€: http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2")

# åˆå§‹åŒ– dlib çš„è‡‰éƒ¨åµæ¸¬å™¨å’Œç‰¹å¾µé»é æ¸¬å™¨
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor('shape_predictor_81_face_landmarks.dat')
print("âœ… dlib æ¨¡å‹è¼‰å…¥æˆåŠŸ")

def optimize_image_size(image, max_size=1024):
    """å„ªåŒ–åœ–ç‰‡å°ºå¯¸ä»¥æå‡è™•ç†é€Ÿåº¦"""
    height, width = image.shape[:2]
    if max(height, width) <= max_size:
        return image
    
    # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹
    scale = max_size / max(height, width)
    new_width = int(width * scale)
    new_height = int(height * scale)
    
    # ä½¿ç”¨ INTER_AREA é€²è¡Œç¸®æ”¾ï¼ˆé©åˆç¸®å°ï¼‰
    resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
    print(f"ğŸ“ åœ–ç‰‡å·²å„ªåŒ–: {width}x{height} -> {new_width}x{new_height}")
    return resized

def rgb_to_hsv(rgb):
    """å°‡RGBè½‰æ›ç‚ºHSV"""
    r, g, b = rgb[0]/255.0, rgb[1]/255.0, rgb[2]/255.0
    return colorsys.rgb_to_hsv(r, g, b)

def hsv_to_rgb(hsv):
    """å°‡HSVè½‰æ›ç‚ºRGB"""
    r, g, b = colorsys.hsv_to_rgb(hsv[0], hsv[1], hsv[2])
    return (int(r*255), int(g*255), int(b*255))

def get_dominant_colors(image, k=1, mask=None):
    """
    ç²å–æŒ‡å®šé®ç½©å€åŸŸçš„ã€Œå¹³å‡é¡è‰²ã€ã€‚
    """
    
    # å¦‚æœæ²’æœ‰é®ç½©ï¼Œç›´æ¥å›å‚³é è¨­é¡è‰² (é¿å…è¨ˆç®—æ•´å¼µåœ–çš„å¹³å‡è‰²)
    if mask is None:
        return [(128, 128, 128)]
    
    # ä½¿ç”¨ cv2.mean è¨ˆç®—é®ç½©å€åŸŸçš„å¹³å‡ BGR å€¼
    # mean() å›å‚³ (B, G, R, Alpha)
    mean_bgr = cv2.mean(image, mask=mask)
    
    # **é—œéµä¿®æ­£**ï¼šå°‡ BGR è½‰æ›ç‚º RGB
    # mean_bgr[0] æ˜¯ B, [1] æ˜¯ G, [2] æ˜¯ R
    mean_rgb = (mean_bgr[2], mean_bgr[1], mean_bgr[0])

    # å°‡çµæœæ”¾å…¥ä¸€å€‹ list ä¸­ï¼Œä»¥ç¬¦åˆå‡½å¼åŸæœ‰çš„å›å‚³æ ¼å¼
    # å°‡é¡è‰²è½‰æ›ç‚ºæ•´æ•¸å…ƒçµ„
    dominant_color = [tuple(map(int, mean_rgb))]
    
    return dominant_color

def detect_face_landmarks(image):
    """æª¢æ¸¬è‡‰éƒ¨ç‰¹å¾µé»"""
    if predictor is None:
        return None, None
    
    # è½‰æ›ç‚ºç°åº¦åœ–
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # æª¢æ¸¬è‡‰éƒ¨
    faces = detector(gray)
    
    if len(faces) == 0:
        return None, None
    
    # å–ç¬¬ä¸€å€‹æª¢æ¸¬åˆ°çš„è‡‰éƒ¨
    face = faces[0]
    
    # ç²å–68å€‹ç‰¹å¾µé»
    landmarks = predictor(gray, face)
    
    return face, landmarks

def get_landmark_points(landmarks):
    """å°‡ dlib landmarks è½‰æ›ç‚º (x, y) åº§æ¨™é»çš„ list"""
    points = []
    for i in range(landmarks.num_parts):
        point = landmarks.part(i)
        points.append((point.x, point.y))
    return points

def extract_skin_region(image, landmarks):
    """
    é‡å° 81 é»æ¨¡å‹å„ªåŒ–è‡‰å‹/ä¸‹å·´é®ç½©ï¼Œè‹¥ä¸è¶³81é»å‰‡fallbackå›68é»é®ç½©ã€‚
    """
    if landmarks is None:
        return None
    points = get_landmark_points(landmarks)
    if len(points) >= 82:  # 81é»æ¨¡å‹
        jaw_points = [*range(0, 17), 79, 80, 81]
        jaw_pts = np.array([points[i] for i in jaw_points if i < len(points)], dtype=np.int32)
        face_mask = np.zeros(image.shape[:2], dtype=np.uint8)
        cv2.fillConvexPoly(face_mask, cv2.convexHull(jaw_pts), 255)
        # æ’é™¤äº”å®˜
        cv2.fillConvexPoly(face_mask, np.array(points[36:42], dtype=np.int32), 0)
        cv2.fillConvexPoly(face_mask, np.array(points[42:48], dtype=np.int32), 0)
        cv2.fillConvexPoly(face_mask, np.array(points[17:22], dtype=np.int32), 0)
        cv2.fillConvexPoly(face_mask, np.array(points[22:27], dtype=np.int32), 0)
        # å˜´å”‡ï¼ˆæ–°ï¼š48-67+69-78ï¼‰
        lip_points = [*range(48, 68), *range(69, 79)]
        lip_pts = np.array([points[i] for i in lip_points if i < len(points)], dtype=np.int32)
        cv2.fillConvexPoly(face_mask, lip_pts, 0)
        return face_mask
    else:  # fallback 68é»
        face_outline_pts = np.array(points[0:17], dtype=np.int32)
        face_mask = np.zeros(image.shape[:2], dtype=np.uint8)
        cv2.fillConvexPoly(face_mask, cv2.convexHull(face_outline_pts), 255)
        # æ’é™¤äº”å®˜
        cv2.fillConvexPoly(face_mask, np.array(points[36:42], dtype=np.int32), 0)
        cv2.fillConvexPoly(face_mask, np.array(points[42:48], dtype=np.int32), 0)
        cv2.fillConvexPoly(face_mask, np.array(points[17:22], dtype=np.int32), 0)
        cv2.fillConvexPoly(face_mask, np.array(points[22:27], dtype=np.int32), 0)
        cv2.fillConvexPoly(face_mask, np.array(points[48:68], dtype=np.int32), 0)
        return face_mask

def extract_eye_regions(image, landmarks):
    """æå–çœ¼ç›å€åŸŸ"""
    if landmarks is None:
        return []
    
    points = get_landmark_points(landmarks)
    eye_regions = []
    
    # å·¦çœ¼ (36-41)
    left_eye_points = np.array(points[36:42], dtype=np.int32)
    # å³çœ¼ (42-47)
    right_eye_points = np.array(points[42:48], dtype=np.int32)
    
    for eye_points in [left_eye_points, right_eye_points]:
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        
        # ä½¿ç”¨å‡¸åŒ…æ›´ç²¾æº–æ¡†é¸çœ¼ç›
        hull = cv2.convexHull(eye_points)
        cv2.fillConvexPoly(mask, hull, 255)
        eye_regions.append(mask)
    
    return eye_regions

def extract_lip_region(image, landmarks):
    """
    é‡å° 81 é»æ¨¡å‹å„ªåŒ–å˜´å”‡é®ç½©ï¼Œè‹¥ä¸è¶³81é»å‰‡fallbackå›68é»é®ç½©ã€‚
    """
    if landmarks is None:
        return None
    points = get_landmark_points(landmarks)
    if len(points) >= 79:  # 81é»æ¨¡å‹
        lip_points = [*range(48, 68), *range(69, 79)]
        lip_pts = np.array([points[i] for i in lip_points if i < len(points)], dtype=np.int32)
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        cv2.fillConvexPoly(mask, lip_pts, 255)
        return mask
    else:  # fallback 68é»
        lip_points = np.array(points[48:68], dtype=np.int32)
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        cv2.fillConvexPoly(mask, lip_points, 255)
        return mask

def extract_hair_mask_bisenet(image):
    """ä½¿ç”¨ BiSeNet æå–é ­é«®é®ç½©"""
    try:
        model = get_bisenet_model()
        
        # é è™•ç†åœ–ç‰‡
        img = cv2.resize(image, (512, 512))
        img = img.transpose((2, 0, 1)).astype(np.float32) / 255.0
        img = torch.from_numpy(img).unsqueeze(0).to(DEVICE)
        
        # æ¨ç†
        with torch.no_grad():
            out, _, _ = model(img)
            pred = torch.argmax(out, dim=1).squeeze().cpu().numpy()
        
        # é ­é«®é¡åˆ¥ç‚º 17
        hair_mask = (pred == 17).astype(np.uint8) * 255
        
        # èª¿æ•´å›åŸå§‹å°ºå¯¸
        hair_mask = cv2.resize(hair_mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)
        
        return hair_mask
    except Exception as e:
        print(f"âš ï¸ BiSeNet é ­é«®æå–å¤±æ•—: {e}")
        return None

def extract_hair_region(image, landmarks, face_rect):
    """ä½¿ç”¨å‚³çµ±æ–¹æ³•æå–é ­é«®å€åŸŸï¼ˆfallbackï¼‰"""
    if landmarks is None or face_rect is None:
        return None
    
    points = get_landmark_points(landmarks)
    
    # å®šç¾©é ­é«®å€åŸŸçš„é—œéµé»
    hair_points = []
    
    # é¡é ­å€åŸŸ (68é»æ¨¡å‹: 17-21, 22-26)
    if len(points) >= 27:
        hair_points.extend(points[17:22])  # å·¦çœ‰æ¯›
        hair_points.extend(points[22:27])  # å³çœ‰æ¯›
    
    # é ­é ‚å€åŸŸï¼ˆä¼°è¨ˆï¼‰
    if len(points) >= 27:
        # ä½¿ç”¨çœ‰æ¯›ä¸­é»å‘ä¸Šå»¶ä¼¸
        left_brow_center = points[19]
        right_brow_center = points[24]
        brow_center = ((left_brow_center[0] + right_brow_center[0]) // 2,
                      (left_brow_center[1] + right_brow_center[1]) // 2)
        
        # å‘ä¸Šå»¶ä¼¸ç´„ 1.5 å€è‡‰éƒ¨é«˜åº¦
        face_height = face_rect.height()
        hair_top = (brow_center[0], max(0, brow_center[1] - int(face_height * 1.5)))
        
        hair_points.append(hair_top)
    
    if len(hair_points) < 3:
        return None
    
    # å‰µå»ºé ­é«®é®ç½©
    hair_mask = np.zeros(image.shape[:2], dtype=np.uint8)
    hair_pts = np.array(hair_points, dtype=np.int32)
    cv2.fillConvexPoly(hair_mask, cv2.convexHull(hair_pts), 255)
    
    return hair_mask

def gray_world_white_balance(img):
    # ç°ä¸–ç•Œå‡è¨­è‡ªå‹•ç™½å¹³è¡¡
    result = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    avg_a = np.average(result[:, :, 1])
    avg_b = np.average(result[:, :, 2])
    result[:, :, 1] = result[:, :, 1] - ((avg_a - 128) * (result[:, :, 0] / 255.0) * 1.1)
    result[:, :, 2] = result[:, :, 2] - ((avg_b - 128) * (result[:, :, 0] / 255.0) * 1.1)
    result = cv2.cvtColor(result, cv2.COLOR_LAB2BGR)
    return result

def mask_skin_pixels(image, mask):
    # YCrCb è†šè‰²åƒç´ éæ¿¾
    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)
    lower = np.array([0, 133, 77], dtype=np.uint8)
    upper = np.array([255, 173, 127], dtype=np.uint8)
    skin_mask = cv2.inRange(ycrcb, lower, upper)
    return cv2.bitwise_and(mask, skin_mask)

def calculate_skin_tone(image, landmarks):
    """è¨ˆç®—è†šè‰²ï¼ˆå„ªåŒ–ç‰ˆæœ¬ï¼‰"""
    skin_mask = extract_skin_region(image, landmarks)
    if skin_mask is None:
        return (128, 128, 128)
    
    # æ‡‰ç”¨è†šè‰²åƒç´ éæ¿¾
    filtered_mask = mask_skin_pixels(image, skin_mask)
    
    # è¨ˆç®—å¹³å‡è†šè‰²
    skin_colors = get_dominant_colors(image, mask=filtered_mask)
    return skin_colors[0] if skin_colors else (128, 128, 128)

def create_debug_image_dlib(image, face_rect, skin_mask, eye_masks, lip_mask, hair_mask, output_path):
    """å‰µå»ºèª¿è©¦åœ–ç‰‡ï¼ˆå„ªåŒ–ç‰ˆæœ¬ï¼‰"""
    debug_img = image.copy()
    
    # å®šç¾©é¡è‰²
    SKIN_COLOR = (0, 255, 0)    # ç¶ è‰²
    EYE_COLOR = (255, 0, 0)     # è—è‰²
    LIP_COLOR = (0, 0, 255)     # ç´…è‰²
    HAIR_COLOR = (255, 255, 0)  # é’è‰²
    
    # ç¹ªè£½é®ç½©
    if skin_mask is not None:
        skin_overlay = np.zeros_like(debug_img)
        skin_overlay[skin_mask == 255] = SKIN_COLOR
        cv2.addWeighted(debug_img, 1, skin_overlay, 0.3, 0, debug_img)
    
    if eye_masks:
        for eye_mask in eye_masks:
            eye_overlay = np.zeros_like(debug_img)
            eye_overlay[eye_mask == 255] = EYE_COLOR
            cv2.addWeighted(debug_img, 1, eye_overlay, 0.5, 0, debug_img)
    
    if lip_mask is not None:
        lip_overlay = np.zeros_like(debug_img)
        lip_overlay[lip_mask == 255] = LIP_COLOR
        cv2.addWeighted(debug_img, 1, lip_overlay, 0.5, 0, debug_img)
    
    if hair_mask is not None:
        hair_overlay = np.zeros_like(debug_img)
        hair_overlay[hair_mask == 255] = HAIR_COLOR
        cv2.addWeighted(debug_img, 1, hair_overlay, 0.4, 0, debug_img)
    
    cv2.imwrite(output_path, debug_img)

def create_debug_mask_image(image, skin_mask=None, eye_masks=None, lip_mask=None, hair_mask=None, output_path='debug_mask.png'):
    """å‰µå»ºèª¿è©¦é®ç½©åœ–ç‰‡ï¼ˆå„ªåŒ–ç‰ˆæœ¬ï¼‰"""
    debug_img = np.zeros_like(image)
    
    # å®šç¾©é¡è‰²
    SKIN_COLOR = (0, 255, 0)    # ç¶ è‰²
    EYE_COLOR = (255, 0, 0)     # è—è‰²
    LIP_COLOR = (0, 0, 255)     # ç´…è‰²
    HAIR_COLOR = (255, 255, 0)  # é’è‰²
    
    # ç¹ªè£½é®ç½©
    if skin_mask is not None:
        skin_overlay = np.zeros_like(debug_img)
        skin_overlay[skin_mask == 255] = SKIN_COLOR
        cv2.addWeighted(debug_img, 1, skin_overlay, 0.5, 0, debug_img)
    
    if eye_masks:
        for eye_mask in eye_masks:
            eye_overlay = np.zeros_like(debug_img)
            eye_overlay[eye_mask == 255] = EYE_COLOR
            cv2.addWeighted(debug_img, 1, eye_overlay, 0.5, 0, debug_img)
    
    if lip_mask is not None:
        lip_overlay = np.zeros_like(debug_img)
        lip_overlay[lip_mask == 255] = LIP_COLOR
        cv2.addWeighted(debug_img, 1, lip_overlay, 0.5, 0, debug_img)
    
    if hair_mask is not None:
        hair_overlay = np.zeros_like(debug_img)
        hair_overlay[hair_mask == 255] = HAIR_COLOR
        cv2.addWeighted(debug_img, 1, hair_overlay, 0.4, 0, debug_img)
    
    cv2.imwrite(output_path, debug_img)

def analyze_seasonal_colors(skin_tone, eye_color, hair_color):
    """åˆ†æå­£ç¯€æ€§è‰²å½©"""
    # è½‰æ›ç‚ºHSVé€²è¡Œåˆ†æ
    skin_hsv = rgb_to_hsv(skin_tone)
    eye_hsv = rgb_to_hsv(eye_color)
    hair_hsv = rgb_to_hsv(hair_color)
    
    # åˆ†æè†šè‰²çš„è‰²èª¿å’Œé£½å’Œåº¦
    skin_hue = skin_hsv[0] * 360  # è½‰æ›ç‚ºåº¦æ•¸
    skin_sat = skin_hsv[1]
    skin_val = skin_hsv[2]
    
    # å­£ç¯€æ€§è‰²å½©åˆ¤æ–·é‚è¼¯
    if skin_hue < 30 or skin_hue > 330:  # åç´…/æ©™
        if skin_sat > 0.3:  # é£½å’Œåº¦è¼ƒé«˜
            season = "spring"
        else:
            season = "autumn"
    elif 30 <= skin_hue <= 90:  # åé»ƒ
        if skin_val > 0.6:  # äº®åº¦è¼ƒé«˜
            season = "spring"
        else:
            season = "autumn"
    elif 90 <= skin_hue <= 150:  # åç¶ 
        season = "summer"
    elif 150 <= skin_hue <= 270:  # åè—/ç´«
        season = "winter"
    else:  # 270-330 åç´«/ç´…
        season = "winter"
    
    return season, {
        'skin_hsv': skin_hsv,
        'eye_hsv': eye_hsv,
        'hair_hsv': hair_hsv
    }

def get_color_palette(season):
    """æ ¹æ“šå­£ç¯€ç²å–å»ºè­°è‰²æ¿"""
    palettes = {
        "spring": {
            "clothes": ["#FF6B6B", "#4ECDC4", "#45B7D1", "#96CEB4", "#FFEAA7"],
            "makeup": ["#FFB6C1", "#FFC0CB", "#FF69B4", "#FF1493", "#DC143C"],
            "jewelry": ["#FFD700", "#FFA500", "#FF6347", "#FF4500"],
            "avoid": ["#000080", "#191970", "#483D8B", "#6A5ACD"]
        },
        "summer": {
            "clothes": ["#87CEEB", "#98FB98", "#DDA0DD", "#F0E68C", "#FFB6C1"],
            "makeup": ["#E6E6FA", "#D8BFD8", "#DDA0DD", "#EE82EE", "#DA70D6"],
            "jewelry": ["#C0C0C0", "#E6E6FA", "#F0F8FF", "#F5F5DC"],
            "avoid": ["#FF4500", "#FF6347", "#FF8C00", "#FFA500"]
        },
        "autumn": {
            "clothes": ["#8B4513", "#A0522D", "#CD853F", "#D2691E", "#B8860B"],
            "makeup": ["#DEB887", "#F4A460", "#DAA520", "#B8860B", "#CD853F"],
            "jewelry": ["#B8860B", "#DAA520", "#CD853F", "#8B4513"],
            "avoid": ["#00CED1", "#40E0D0", "#48D1CC", "#20B2AA"]
        },
        "winter": {
            "clothes": ["#000080", "#191970", "#483D8B", "#6A5ACD", "#9370DB"],
            "makeup": ["#FF1493", "#DC143C", "#B22222", "#8B0000", "#FF4500"],
            "jewelry": ["#C0C0C0", "#FFFFFF", "#000000", "#4169E1"],
            "avoid": ["#FFD700", "#FFA500", "#FF6347", "#FF4500"]
        }
    }
    
    return palettes.get(season, palettes["spring"])

def rgb_to_hex(rgb):
    """å°‡RGBè½‰æ›ç‚ºåå…­é€²åˆ¶"""
    return '#%02x%02x%02x' % rgb

def get_color_names_from_gemini(hex_colors):
    """å¾ Gemini ç²å–é¡è‰²åç¨±ï¼ˆå„ªåŒ–ç‰ˆæœ¬ï¼‰"""
    try:
        genai.configure(api_key=os.environ["GEMINI_API_KEY"])
        prompt = (
            "è«‹å¹«æˆ‘åˆ¤æ–·ä»¥ä¸‹è‰²ç¢¼çš„ç¹é«”ä¸­æ–‡åç¨±ï¼Œå›å‚³æ ¼å¼ç‚º JSON ç‰©ä»¶ï¼Œkey ç‚ºè‰²ç¢¼ï¼Œvalue ç‚ºä¸­æ–‡åç¨±ï¼š\n"
            + ", ".join(hex_colors)
        )
        model = genai.GenerativeModel("gemini-2.0-flash")
        response = model.generate_content(prompt)
        # è§£æ Gemini å›å‚³çš„ JSON å…§å®¹
        match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if match:
            return json.loads(match.group(0))
        else:
            return {c: "æœªçŸ¥è‰²å" for c in hex_colors}
    except Exception as e:
        print(f"âš ï¸ Gemini è‰²åæŸ¥è©¢å¤±æ•—: {e}")
        return {c: "æœªçŸ¥è‰²å" for c in hex_colors}

def process_image_parallel(image, landmarks, face):
    """ä¸¦è¡Œè™•ç†åœ–ç‰‡åˆ†æ"""
    with ThreadPoolExecutor(max_workers=4) as executor:
        # æäº¤ä¸¦è¡Œä»»å‹™
        skin_future = executor.submit(calculate_skin_tone, image, landmarks)
        eye_future = executor.submit(extract_eye_regions, image, landmarks)
        lip_future = executor.submit(extract_lip_region, image, landmarks)
        hair_future = executor.submit(extract_hair_mask_bisenet, image)
        
        # ç­‰å¾…çµæœ
        skin_tone = skin_future.result()
        eye_masks = eye_future.result()
        lip_mask = lip_future.result()
        hair_mask = hair_future.result()
        
        # è™•ç†çœ¼ç›é¡è‰²
        all_eye_colors = []
        if eye_masks:
            for eye_mask in eye_masks:
                all_eye_colors.extend(get_dominant_colors(image, mask=eye_mask))
        eye_color = all_eye_colors[0] if all_eye_colors else (128, 128, 128)
        
        # è™•ç†å…¶ä»–é¡è‰²
        lip_color = get_dominant_colors(image, mask=lip_mask)[0] if lip_mask is not None else (128, 128, 128)
        hair_color = get_dominant_colors(image, mask=hair_mask)[0] if hair_mask is not None else (128, 128, 128)
        
        return skin_tone, eye_color, lip_color, hair_color, eye_masks, lip_mask, hair_mask

@app.route('/analyze', methods=['POST'])
def analyze():
    if 'photo' not in request.files:
        return jsonify({"error": "è«‹æ±‚ä¸­ç¼ºå°‘åœ–ç‰‡æª”æ¡ˆ"}), 400
    file = request.files['photo']
    if file.filename == '':
        return jsonify({"error": "æœªé¸æ“‡æª”æ¡ˆ"}), 400

    start_time = time.time()
    print(f"ğŸš€ é–‹å§‹åˆ†æåœ–ç‰‡: {file.filename}")

    # Save uploaded file
    filename = f"upload_{uuid.uuid4().hex}.jpg"
    file_path = os.path.join(UPLOADS_DIR, filename)
    file.save(file_path)

    # Read image
    image = cv2.imread(file_path)
    if image is None:
        return jsonify({"error": "ç„¡æ³•è®€å–åœ–ç‰‡æª”æ¡ˆ"}), 500

    try:
        # å„ªåŒ–åœ–ç‰‡å°ºå¯¸
        image = optimize_image_size(image, max_size=1024)
        
        # --- 1. Face and Landmark Detection ---
        print("ğŸ” æª¢æ¸¬è‡‰éƒ¨ç‰¹å¾µé»...")
        face, landmarks = detect_face_landmarks(image)
        if landmarks is None:
            return jsonify({"error": "æœªåµæ¸¬åˆ°è‡‰éƒ¨ç‰¹å¾µé»ï¼Œè«‹ä½¿ç”¨æ›´æ¸…æ™°çš„æ­£é¢ç…§ã€‚"}), 400

        # --- 2. ä¸¦è¡Œåˆ†æé¡è‰² ---
        print("ğŸ¨ åˆ†æé¡è‰²...")
        skin_tone, eye_color, lip_color, hair_color, eye_masks, lip_mask, hair_mask = process_image_parallel(image, landmarks, face)

        # --- 3. Gemini æŸ¥è©¢è‰²åï¼ˆå¯é¸ï¼Œå¦‚æœå¤±æ•—ä¸å½±éŸ¿ä¸»è¦åˆ†æï¼‰ ---
        print("ğŸŒˆ æŸ¥è©¢é¡è‰²åç¨±...")
        hex_colors = [
            rgb_to_hex(skin_tone),
            rgb_to_hex(eye_color),
            rgb_to_hex(hair_color),
            rgb_to_hex(lip_color)
        ]
        color_names = get_color_names_from_gemini(hex_colors)

        # --- 4. Seasonal Analysis ---
        print("ğŸŒ¤ï¸ åˆ†æå­£ç¯€æ€§è‰²å½©...")
        season, analysis_details = analyze_seasonal_colors(skin_tone, eye_color, hair_color)

        # --- 5. å¯é¸ï¼šå‰µå»º Debug åœ–ç‰‡ï¼ˆåƒ…åœ¨éœ€è¦æ™‚ï¼‰ ---
        debug_image_url = ""
        debug_mask_url = ""
        if os.environ.get('DEBUG_MODE', 'false').lower() == 'true':
            print("ğŸ“¸ å‰µå»ºèª¿è©¦åœ–ç‰‡...")
            skin_mask_for_debug = extract_skin_region(image, landmarks)
            debug_image_filename = f"debug_{uuid.uuid4().hex}.jpg"
            debug_image_path = os.path.join(DEBUG_OUTPUT_DIR, debug_image_filename)
            create_debug_image_dlib(image, face, skin_mask_for_debug, eye_masks, lip_mask, hair_mask, debug_image_path)
            debug_image_url = f"/debug/{debug_image_filename}"

            debug_mask_filename = f"debug_mask_{uuid.uuid4().hex}.png"
            debug_mask_path = os.path.join(DEBUG_OUTPUT_DIR, debug_mask_filename)
            create_debug_mask_image(image, skin_mask_for_debug, eye_masks, lip_mask, hair_mask, debug_mask_path)
            debug_mask_url = f"/debug/{debug_mask_filename}"

        # --- 6. Prepare Response ---
        response_data = {
            "skin_tone": rgb_to_hex(skin_tone),
            "eye_color": rgb_to_hex(eye_color),
            "hair_color": rgb_to_hex(hair_color),
            "lip_color": rgb_to_hex(lip_color),
            "color_names": color_names,
            "season": season,
            "season_name": {"spring": "æ˜¥å­£å‹", "summer": "å¤å­£å‹", "autumn": "ç§‹å­£å‹", "winter": "å†¬å­£å‹"}.get(season, "åˆ†æå¤±æ•—"),
            "color_suggestions": get_color_palette(season),
            "analysis_details": analysis_details,
            "debug_image_url": debug_image_url,
            "debug_mask_url": debug_mask_url,
            "debug_error": "",
            "processing_time": round(time.time() - start_time, 2)
        }
        
        print(f"âœ… åˆ†æå®Œæˆï¼Œè€—æ™‚ {response_data['processing_time']} ç§’")
        return jsonify(response_data)

    except Exception as e:
        import traceback
        print(f"âŒ åˆ†æå¤±æ•—: {e}")
        print(traceback.format_exc())
        return jsonify({"error": f"ä¼ºæœå™¨åœ¨é€²éšåˆ†æä¸­ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}"}), 500
    finally:
        # Clean up the uploaded file
        if os.path.exists(file_path):
            os.remove(file_path)

@app.route('/debug/<filename>')
def serve_debug_image(filename):
    return send_from_directory(DEBUG_OUTPUT_DIR, filename)

if __name__ == '__main__':
    # ... (add predictor file check)
    app.run(host='0.0.0.0', port=5001, threaded=True)